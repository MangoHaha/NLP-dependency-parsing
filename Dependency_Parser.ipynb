{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dependency_Parser.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MangoHaha/NLP-dependency-parsing/blob/master/Dependency_Parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "pIuhV5tg0fwp",
        "colab_type": "code",
        "outputId": "22ae4ecb-1b04-40fc-ad11-a6ac0c005132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/88/8e5f4cfb99a4186b4b7f06aa1294353e0be6b05b25802a82f3d16cb30b79/pyspark-2.4.2.tar.gz (193.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 193.9MB 80kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K    100% |████████████████████████████████| 204kB 27.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/dc/0e/02/e9fdf0bf3ad20284175307d4ab31afcf967604f25f3b4f1d96\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KTQ3V-Xf1B4E",
        "colab_type": "code",
        "outputId": "3534b543-4bf7-49ee-afa5-d50a3f40ccc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark import SparkContext\n",
        "sc = SparkContext(\"local\", \"Data Prepare\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bb049a4b5ee1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"local\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Data Prepare\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: No module named pyspark",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "rTNI4SD8tmmk",
        "colab_type": "code",
        "outputId": "f76b3fea-1b9f-48fa-8b4d-6f841813b97f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hXoklQCeyWUw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vVoUMjpYyAS2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DataSet:\n",
        "  \n",
        "  \n",
        "  def __init__(self): \n",
        "    self.dev_data = pd.read_csv('/content/drive/My Drive/NLP/data/dev.data', sep=\" \", header=None)\n",
        "    self.train_data = pd.read_csv('/content/drive/My Drive/NLP/data/train.data', sep=\" \", header=None)\n",
        "    self.vocabs_action = pd.read_csv('/content/drive/My Drive/NLP/data/vocabs.actions', sep=\" \", header=None)\n",
        "    self.vocabs_pos = pd.read_csv('/content/drive/My Drive/NLP/data/vocabs.pos', sep=\" \", header=None)\n",
        "    self.vocabs_label = pd.read_csv('/content/drive/My Drive/NLP/data/vocabs.labels', sep=\" \", header=None)\n",
        "    self.vocabs_word = pd.read_csv('/content/drive/My Drive/NLP/data/vocabs.word', sep=\" \", header=None)\n",
        "    self.word_train = self.prepare_data(self.train_data, self.vocabs_word, 0, 20)\n",
        "    self.pos_train = self.prepare_data(self.train_data, self.vocabs_pos, 20, 40)\n",
        "    self.label_train = self.prepare_data(self.train_data, self.vocabs_label, 40, 52)\n",
        "    self.action_train = self.prepare_data(self.train_data, self.vocabs_action, 52, 53)\n",
        "    self.word_dev = self.prepare_data(self.dev_data, self.vocabs_word, 0, 20)\n",
        "    self.pos_dev = self.prepare_data(self.dev_data, self.vocabs_pos, 20, 40)\n",
        "    self.label_dev = self.prepare_data(self.dev_data, self.vocabs_label, 40, 52)\n",
        "    self.action_dev = self.prepare_data(self.dev_data, self.vocabs_action, 52, 53)\n",
        "\n",
        "  def prepare_data(self, data, vocabs, start, end):\n",
        "    sub_data = data.iloc[:,start:end]\n",
        "    voc = dict(zip(vocabs.iloc[:,0], vocabs.iloc[:,1]))\n",
        "    new_array = []\n",
        "    for line in sub_data.itertuples():\n",
        "    #for line in sub_data.itertuples():\n",
        "      cur_array = []\n",
        "      for word in line[1:]:\n",
        "        if word in voc:\n",
        "          cur_array.append(voc.get(word))\n",
        "        else:\n",
        "          cur_array.append(0)\n",
        "      new_array.append(cur_array)\n",
        "    return pd.DataFrame(new_array)\n",
        "  \n",
        "  def prepare_data_predict(self, data, vocabs, start, end):\n",
        "    sub_data = data[start:end]\n",
        "    voc = dict(zip(vocabs.iloc[:,0], vocabs.iloc[:,1]))\n",
        "    new_array = []\n",
        "    #for line in sub_data.head(20).itertuples():\n",
        "    for word in sub_data:\n",
        "      if word in voc:\n",
        "        new_array.append(voc.get(word))\n",
        "      else:\n",
        "        new_array.append(1)\n",
        "    return pd.DataFrame(new_array)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oa_Ii5CbMAD-",
        "colab_type": "code",
        "outputId": "9ead37cc-859b-43fa-ec2a-779babfaf4fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from numpy import argmax\n",
        "# integer encode input data\n",
        "dataset = DataSet()\n",
        "#print(dataset.word_train.values.tolist())\n",
        "# one hot encode\n",
        "#onehot_encoded = []\n",
        "#for value in dataset.word_train.values.tolist():\n",
        "#  for index in value:\n",
        "#    letter = [0 for _ in range(len(dataset.vocabs_word))]\n",
        "#    letter[index] = 1\n",
        "#    onehot_encoded.append(letter)\n",
        "#  print(value)\n",
        "\n",
        "#print(len(onehot_encoded[0]))\n",
        "\n",
        "word_oh_encoder = OneHotEncoder()\n",
        "encoded_val = word_oh_encoder.word_oh_encoder(dataset.word_train.values.tolist()[0])\n",
        "print(len(encoded_val[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8EiYheJ35ccc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YQ-Cjr1lJpi7",
        "colab_type": "code",
        "outputId": "466e2274-de72-4fbd-b2f2-62c5eb803342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "x = [[2,3,4,5,6,7]]\n",
        "print(x)\n",
        "enc = preprocessing.OneHotEncoder()\n",
        "enc.fit(x)\n",
        "onehotlabels = enc.transform(x).toarray()\n",
        "print(onehotlabels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2, 3, 4, 5, 6, 7]]\n",
            "[[1. 1. 1. 1. 1. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EWmAk093IrN0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NetProperties:\n",
        "    def __init__(self, word_embed_dim, pos_embed_dim, label_embed_dim, hidden_dim, minibatch_size, epoch):\n",
        "        self.word_embed_dim = word_embed_dim\n",
        "        self.pos_embed_dim = pos_embed_dim\n",
        "        self.label_embed_dim = label_embed_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.minibatch_size = minibatch_size\n",
        "        self.epoch = epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mJUalkT8I8Ou",
        "colab_type": "code",
        "outputId": "f1058355-1aef-4843-ad41-b337572ac9da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install dynet\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dynet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/2c/6b773466b4cca5092b3fac49969011a720e6ca7b01bcfd286ac412a62971/dyNET-2.1-cp27-cp27mu-manylinux1_x86_64.whl (27.9MB)\n",
            "\u001b[K     |████████████████████████████████| 27.9MB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from dynet) (1.16.3)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python2.7/dist-packages (from dynet) (0.29.7)\n",
            "Installing collected packages: dynet\n",
            "Successfully installed dynet-2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U2q8gqLwIsle",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import dynet as dynet\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "class Network:\n",
        "    def __init__(self, properties, dataset):\n",
        "        self.properties = properties\n",
        "        self.dataset = dataset\n",
        "        #self.tag2action = dict(zip(dataset.vocabs_action.iloc[:,1], dataset.vocabs_action.iloc[:,0]))\n",
        "\n",
        "\n",
        "        # first initialize a computation graph container (or model).\n",
        "        self.model = dynet.Model()\n",
        "\n",
        "        # assign the algorithm for backpropagation updates.\n",
        "        self.updater = dynet.AdamTrainer(self.model)\n",
        "\n",
        "        # create embeddings for words and tag features.\n",
        "        self.word_embedding = self.model.add_lookup_parameters((dataset.vocabs_word.shape[0], properties.word_embed_dim))\n",
        "        self.pos_embedding = self.model.add_lookup_parameters((dataset.vocabs_pos.shape[0], properties.pos_embed_dim))\n",
        "        self.label_embedding = self.model.add_lookup_parameters((dataset.vocabs_label.shape[0], properties.label_embed_dim))\n",
        "\n",
        "\n",
        "        # assign transfer function \n",
        "        self.transfer = dynet.rectify  # can be dynet.logistic or dynet.tanh as well.\n",
        "\n",
        "        # define the input dimension for the embedding layer.\n",
        "        # here we assume to see two words after and before and current word (meaning 5 word embeddings)\n",
        "        # and to see the last two predicted tags (meaning two tag embeddings)\n",
        "        #self.input_dim = 5 * properties.word_embed_dim + 2 * properties.pos_embed_dim\n",
        "        self.input_dim = 20 * (properties.word_embed_dim + properties.pos_embed_dim) + 12*properties.label_embed_dim\n",
        "\n",
        "\n",
        "        # define the hidden layer.\n",
        "        self.hidden_layer1 = self.model.add_parameters((properties.hidden_dim, self.input_dim))\n",
        "\n",
        "        # define the hidden layer bias term and initialize it as constant 0.2.\n",
        "        self.hidden_layer_bias1 = self.model.add_parameters(properties.hidden_dim, init=dynet.ConstInitializer(0.2))\n",
        "        \n",
        "        # define the hidden layer.\n",
        "        self.hidden_layer2 = self.model.add_parameters((properties.hidden_dim, properties.hidden_dim))\n",
        "\n",
        "        # define the hidden layer bias term and initialize it as constant 0.2.\n",
        "        self.hidden_layer_bias2 = self.model.add_parameters(properties.hidden_dim, init=dynet.ConstInitializer(0.2))\n",
        "\n",
        "        # define the output weight.\n",
        "        self.output_layer = self.model.add_parameters((dataset.vocabs_action.shape[0], properties.hidden_dim))\n",
        "\n",
        "        # define the bias vector and initialize it as zero.\n",
        "        self.output_bias = self.model.add_parameters(dataset.vocabs_action.shape[0], init=dynet.ConstInitializer(0))\n",
        "\n",
        "    def build_graph(self,index, word, pos, label):\n",
        "\n",
        "        # extract word embeddings and tag embeddings from features\n",
        "        word_embeds = [self.word_embedding[wid] for wid in word.iloc[index]]\n",
        "        pos_embeds = [self.pos_embedding[wid] for wid in pos.iloc[index]]\n",
        "        label_embeds = [self.label_embedding[wid] for wid in label.iloc[index]]\n",
        "\n",
        "        # concatenating all features (recall that '+' for lists is equivalent to appending two lists)\n",
        "        embedding_layer = dynet.concatenate(word_embeds + pos_embeds + label_embeds)\n",
        "        # calculating the hidden layer\n",
        "        # .expr() converts a parameter to a matrix expression in dynet (its a dynet-specific syntax).\n",
        "        hidden1 = self.transfer(self.hidden_layer1 * embedding_layer + self.hidden_layer_bias1)\n",
        "        hidden2 = self.transfer(self.hidden_layer2 * hidden1 + self.hidden_layer_bias2)\n",
        "\n",
        "        # calculating the output layer\n",
        "        output = self.output_layer * hidden2 + self.output_bias.expr()\n",
        "\n",
        "        # return the output as a dynet vector (expression)\n",
        "        return output\n",
        "\n",
        "      \n",
        "    def predict(self, word, pos, label):\n",
        " \n",
        "        #word_oh = self.get_oh_encoder(word, dataset.vocabs_word.values.tolist())\n",
        "    \n",
        "        word_embeds = [self.word_embedding[wid] for wid in word]\n",
        "        pos_embeds = [self.pos_embedding[wid] for wid in pos]\n",
        "        label_embeds = [self.label_embedding[wid] for wid in label]\n",
        "        # concatenating all features (recall that '+' for lists is equivalent to appending two lists)\n",
        "        embedding_layer = dynet.concatenate(word_embeds + pos_embeds + label_embeds)\n",
        "        # calculating the hidden layer\n",
        "        # .expr() converts a parameter to a matrix expression in dynet (its a dynet-specific syntax).\n",
        "        hidden1 = self.transfer(self.hidden_layer1 * embedding_layer + self.hidden_layer_bias1)\n",
        "        hidden2 = self.transfer(self.hidden_layer2 * hidden1 + self.hidden_layer_bias2)\n",
        "\n",
        "        # calculating the output layer\n",
        "        output = self.output_layer.expr() * hidden2 + self.output_bias.expr()\n",
        "\n",
        "        # return the output as a dynet vector (expression)\n",
        "        return output\n",
        "    def train(self):\n",
        "        # matplotlib config\n",
        "        loss_values = []\n",
        "        plt.ion()\n",
        "        ax = plt.gca()\n",
        "        ax.set_xlim([0, 10])\n",
        "        ax.set_ylim([0, 3])\n",
        "        plt.title(\"Loss over time\")\n",
        "        plt.xlabel(\"Minibatch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "\n",
        "        for i in range(self.properties.epoch):\n",
        "            print 'started epoch', (i+1)\n",
        "            losses = []\n",
        "\n",
        "            step = 0\n",
        "            for index in range(dataset.word_train.shape[0]):\n",
        "                gold_label = dataset.action_train.iloc[index]\n",
        "                result = self.build_graph(index, dataset.word_train, dataset.pos_train, dataset.label_train)\n",
        "\n",
        "                # getting loss with respect to negative log softmax function and the gold label.\n",
        "                loss = dynet.pickneglogsoftmax(result, gold_label)\n",
        "\n",
        "                # appending to the minibatch losses\n",
        "                losses.append(loss)\n",
        "                step += 1\n",
        "                #print(\"G\" + gold_label)\n",
        "                #print(result)\n",
        "                #print(len(losses))\n",
        "                if len(losses) >= self.properties.minibatch_size:\n",
        "                    # now we have enough loss values to get loss for minibatch\n",
        "                    minibatch_loss = dynet.esum(losses) / len(losses)\n",
        "\n",
        "                    # calling dynet to run forward computation for all minibatch items\n",
        "                    minibatch_loss.forward()\n",
        "\n",
        "                    # getting float value of the loss for current minibatch\n",
        "                    minibatch_loss_value = minibatch_loss.value()\n",
        "\n",
        "                    # printing info and plotting\n",
        "                    loss_values.append(minibatch_loss_value)\n",
        "                    if len(loss_values)%10==0:\n",
        "                        ax.set_xlim([0, len(loss_values)+10])\n",
        "                        ax.plot(loss_values)\n",
        "                        plt.draw()\n",
        "                        plt.pause(0.0001)\n",
        "                        progress = round(100 * float(step) / len(dataset.train_data), 2)\n",
        "                        print 'current minibatch loss', minibatch_loss_value, 'progress:', progress, '%'\n",
        "\n",
        "                    # calling dynet to run backpropagation\n",
        "                    minibatch_loss.backward()\n",
        "\n",
        "                    # calling dynet to change parameter values with respect to current backpropagation\n",
        "                    self.updater.update()\n",
        "\n",
        "                    # empty the loss vector\n",
        "                    losses = []\n",
        "\n",
        "                    # refresh the memory of dynet\n",
        "                    dynet.renew_cg()\n",
        "\n",
        "            # there are still some minibatch items in the memory but they are smaller than the minibatch size\n",
        "            # so we ask dynet to forget them\n",
        "            dynet.renew_cg()\n",
        "\n",
        "    def decode(self, word_dev, pos_dev, label_dev):\n",
        "        # first putting two start symbols\n",
        "        #tags = ['<s>', '<s>']\n",
        "\n",
        "            # running forward\n",
        "        word_dev.values.reshape(-1)\n",
        "        output = self.predict(word_dev.values.reshape(-1).tolist(), pos_dev.values.reshape(-1).tolist(), label_dev.values.reshape(-1).tolist())\n",
        "\n",
        "            # getting list value of the output\n",
        "        scores = output.npvalue()\n",
        "\n",
        "            # getting best tag\n",
        "        #best_tag_id = np.argmax(scores)\n",
        "\n",
        "            # assigning the best tag\n",
        "        #tags.append(tag2action.get(best_tag_id))\n",
        "\n",
        "            # refresh dynet memory (computation graph)\n",
        "        dynet.renew_cg()\n",
        "\n",
        "        return scores\n",
        "    \n",
        "    def get_oh_encoder(self, input, vocabs):\n",
        "      onehot_encoded = []\n",
        "      for index in input:\n",
        "        letter = [0 for _ in range(len(vocabs))]\n",
        "        letter[index] = 1\n",
        "        onehot_encoded.append(letter)\n",
        "      return onehot_encoded;\n",
        "\n",
        "    def load(self, filename):\n",
        "        self.model.populate(filename)\n",
        "\n",
        "    def save(self, filename):\n",
        "        self.model.save(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y1glAYi2UJnD",
        "colab_type": "code",
        "outputId": "e79a1b63-312b-48f3-df8f-0952ec8292d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3756
        }
      },
      "cell_type": "code",
      "source": [
        "prop = NetProperties(64, 32, 32, 200, 1000, 7)\n",
        "dataset = DataSet();\n",
        "network = Network(prop, dataset)\n",
        "network.train()\n",
        "network.save(\"/content/drive/My Drive/NLP/model.md5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "started epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 2.43445611 progress: 6.96 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 2.05592131615 progress: 13.91 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 1.76919448376 progress: 20.87 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 1.64815282822 progress: 27.82 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 1.35564386845 progress: 34.78 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 1.11026263237 progress: 41.74 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 1.05354964733 progress: 48.69 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.840351045132 progress: 55.65 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.791448116302 progress: 62.61 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.64462429285 progress: 69.56 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.661213517189 progress: 76.52 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.527420163155 progress: 83.47 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.470874190331 progress: 90.43 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.461513906717 progress: 97.39 %\n",
            "started epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.373359233141 progress: 4.87 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.381418943405 progress: 11.83 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.390094339848 progress: 18.78 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.353747725487 progress: 25.74 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.393706530333 progress: 32.69 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.259532421827 progress: 39.65 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.315029889345 progress: 46.61 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.365210682154 progress: 53.56 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.252369910479 progress: 60.52 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.312573134899 progress: 67.47 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.266790449619 progress: 74.43 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.195354282856 progress: 81.39 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.285845041275 progress: 88.34 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.236081257463 progress: 95.3 %\n",
            "started epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.38811314106 progress: 2.78 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.256184458733 progress: 9.74 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.217553421855 progress: 16.69 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.295651257038 progress: 23.65 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.211281016469 progress: 30.61 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.256590783596 progress: 37.56 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.236314252019 progress: 44.52 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.210850849748 progress: 51.48 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.219599545002 progress: 58.43 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.242462828755 progress: 65.39 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.20126478374 progress: 72.34 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.211692869663 progress: 79.3 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.145203053951 progress: 86.26 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.180209353566 progress: 93.21 %\n",
            "started epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.194068565965 progress: 0.7 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.27520313859 progress: 7.65 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.166086271405 progress: 14.61 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.17800450325 progress: 21.56 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.149478703737 progress: 28.52 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.185592636466 progress: 35.48 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.187558993697 progress: 42.43 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.198002547026 progress: 49.39 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.164739906788 progress: 56.34 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.211269125342 progress: 63.3 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.170063376427 progress: 70.26 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.145872429013 progress: 77.21 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.209629014134 progress: 84.17 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.155654549599 progress: 91.13 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.123572826385 progress: 98.08 %\n",
            "started epoch 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.18303476274 progress: 5.56 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.153792589903 progress: 12.52 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.163662970066 progress: 19.48 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.148206874728 progress: 26.43 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.0993551313877 progress: 33.39 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.122204482555 progress: 40.35 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.164488881826 progress: 47.3 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.156613379717 progress: 54.26 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.166958332062 progress: 61.21 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.148876935244 progress: 68.17 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.125720188022 progress: 75.13 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.130760446191 progress: 82.08 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.151893660426 progress: 89.04 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.0939700603485 progress: 95.99 %\n",
            "started epoch 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.140247091651 progress: 3.48 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.188433364034 progress: 10.43 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.232748255134 progress: 17.39 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.136047258973 progress: 24.35 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.131533756852 progress: 31.3 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.140819177032 progress: 38.26 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.142833307385 progress: 45.21 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.164937093854 progress: 52.17 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.128418087959 progress: 59.13 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.113278217614 progress: 66.08 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.150372684002 progress: 73.04 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.0934808403254 progress: 80.0 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.0800439566374 progress: 86.95 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.101732611656 progress: 93.91 %\n",
            "started epoch 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.118239507079 progress: 1.39 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.0925229564309 progress: 8.35 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.0950957387686 progress: 15.3 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.0908848494291 progress: 22.26 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.137527957559 progress: 29.22 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.0852422043681 progress: 36.17 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.128325045109 progress: 43.13 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.0700156837702 progress: 50.08 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.0830074697733 progress: 57.04 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.120910353959 progress: 64.0 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.096031576395 progress: 70.95 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.0973019301891 progress: 77.91 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.0815668031573 progress: 84.86 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.0537418089807 progress: 91.82 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.0742615759373 progress: 98.78 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "frlxKXGg1BSH",
        "colab_type": "code",
        "outputId": "236bb770-31fa-47b9-e235-90bf56c92088",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "cell_type": "code",
      "source": [
        "network.load(\"/content/drive/My Drive/NLP/model.md5\")\n",
        "tag2action = dict(zip(dataset.vocabs_action.iloc[:,1], dataset.vocabs_action.iloc[:,0]))\n",
        "network.decode(dataset.word_dev.values.tolist()[0], dataset.pos_dev.values.tolist()[0], dataset.label_dev.values.tolist()[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-f608db2696cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/NLP/model.md5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtag2action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabs_action\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabs_action\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-56-dcf82fc2c4d1>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, word_dev, pos_dev, label_dev)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;31m# running forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mword_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "gvscNhwzb5dz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DepModel:\n",
        "    def __init__(self):\n",
        "        '''\n",
        "            You can add more arguments for examples actions and model paths.\n",
        "            You need to load your model here.\n",
        "            actions: provides indices for actions.\n",
        "            it has the same order as the data/vocabs.actions file.\n",
        "        '''\n",
        "        # if you prefer to have your own index for actions, change this.\n",
        "        self.actions = ['SHIFT', 'LEFT-ARC:rroot', 'LEFT-ARC:cc', 'LEFT-ARC:number', 'LEFT-ARC:ccomp', 'LEFT-ARC:possessive', 'LEFT-ARC:prt', 'LEFT-ARC:num', 'LEFT-ARC:nsubjpass', 'LEFT-ARC:csubj', 'LEFT-ARC:conj', 'LEFT-ARC:dobj', 'LEFT-ARC:nn', 'LEFT-ARC:neg', 'LEFT-ARC:discourse', 'LEFT-ARC:mark', 'LEFT-ARC:auxpass', 'LEFT-ARC:infmod', 'LEFT-ARC:mwe', 'LEFT-ARC:advcl', 'LEFT-ARC:aux', 'LEFT-ARC:prep', 'LEFT-ARC:parataxis', 'LEFT-ARC:nsubj', 'LEFT-ARC:<null>', 'LEFT-ARC:rcmod', 'LEFT-ARC:advmod', 'LEFT-ARC:punct', 'LEFT-ARC:quantmod', 'LEFT-ARC:tmod', 'LEFT-ARC:acomp', 'LEFT-ARC:pcomp', 'LEFT-ARC:poss', 'LEFT-ARC:npadvmod', 'LEFT-ARC:xcomp', 'LEFT-ARC:cop', 'LEFT-ARC:partmod', 'LEFT-ARC:dep', 'LEFT-ARC:appos', 'LEFT-ARC:det', 'LEFT-ARC:amod', 'LEFT-ARC:pobj', 'LEFT-ARC:iobj', 'LEFT-ARC:expl', 'LEFT-ARC:predet', 'LEFT-ARC:preconj', 'LEFT-ARC:root', 'RIGHT-ARC:rroot', 'RIGHT-ARC:cc', 'RIGHT-ARC:number', 'RIGHT-ARC:ccomp', 'RIGHT-ARC:possessive', 'RIGHT-ARC:prt', 'RIGHT-ARC:num', 'RIGHT-ARC:nsubjpass', 'RIGHT-ARC:csubj', 'RIGHT-ARC:conj', 'RIGHT-ARC:dobj', 'RIGHT-ARC:nn', 'RIGHT-ARC:neg', 'RIGHT-ARC:discourse', 'RIGHT-ARC:mark', 'RIGHT-ARC:auxpass', 'RIGHT-ARC:infmod', 'RIGHT-ARC:mwe', 'RIGHT-ARC:advcl', 'RIGHT-ARC:aux', 'RIGHT-ARC:prep', 'RIGHT-ARC:parataxis', 'RIGHT-ARC:nsubj', 'RIGHT-ARC:<null>', 'RIGHT-ARC:rcmod', 'RIGHT-ARC:advmod', 'RIGHT-ARC:punct', 'RIGHT-ARC:quantmod', 'RIGHT-ARC:tmod', 'RIGHT-ARC:acomp', 'RIGHT-ARC:pcomp', 'RIGHT-ARC:poss', 'RIGHT-ARC:npadvmod', 'RIGHT-ARC:xcomp', 'RIGHT-ARC:cop', 'RIGHT-ARC:partmod', 'RIGHT-ARC:dep', 'RIGHT-ARC:appos', 'RIGHT-ARC:det', 'RIGHT-ARC:amod', 'RIGHT-ARC:pobj', 'RIGHT-ARC:iobj', 'RIGHT-ARC:expl', 'RIGHT-ARC:predet', 'RIGHT-ARC:preconj', 'RIGHT-ARC:root']\n",
        "        # write your code here for additional parameters.\n",
        "        # feel free to add more arguments to the initializer.\n",
        "        prop = NetProperties(64, 32, 32, 200, 1000, 7)\n",
        "        dataset = DataSet();\n",
        "        self.network = Network(prop, dataset)\n",
        "\n",
        "        self.network.load(\"/content/drive/My Drive/NLP/model.md5\")\n",
        "        self.data = DataSet()\n",
        "\n",
        "    def score(self, str_features):\n",
        "        '''\n",
        "        :param str_features: String features\n",
        "        20 first: words, next 20: pos, next 12: dependency labels.\n",
        "        DO NOT ADD ANY ARGUMENTS TO THIS FUNCTION.\n",
        "        :return: list of scores\n",
        "        '''\n",
        "        # change this part of the code.\n",
        "        word = self.data.prepare_data_predict(str_features, self.data.vocabs_word, 0, 20)\n",
        "        pos = self.data.prepare_data_predict(str_features, self.data.vocabs_pos, 20, 40)\n",
        "        label = self.data.prepare_data_predict(str_features, self.data.vocabs_label, 40, 52)\n",
        "        #return [0]*len(self.actions)\n",
        "        scores = self.network.decode(word, pos, label)\n",
        "        #scores = np.reshape(scores,[len(self.actions)])\n",
        "        #print(scores.tolist())\n",
        "        return scores.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vkwbOnT4cD9J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Decoder:\n",
        "    def __init__(self, score_fn, rindex):\n",
        "        self.fn = score_fn\n",
        "        self.map = rindex\n",
        "\n",
        "    def parse(self, f, of):\n",
        "        outputs = []\n",
        "        for k, sen in enumerate(read_conll(f)):\n",
        "            #print(type(sen))\n",
        "            conf = Configuration.parse(sen, self.map, self.fn)\n",
        "            for i, arc in enumerate(conf.arcs[1:]):\n",
        "               sen[i + 1].head, sen[i+1].relation = arc[0], arc[1]\n",
        "            outputs.append(sen)\n",
        "            #print(str(sen))\n",
        "            if (k + 1) % 100 == 0:\n",
        "                sys.stdout.write(str(k + 1) + '...')\n",
        "        sys.stdout.write('\\n')\n",
        "        write_conll(of, outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iWehft7_cJd6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Configuration:\n",
        "    def __init__(self, entries):\n",
        "        self.stack = [0]\n",
        "        self.entries = entries\n",
        "        self.buffer = [e.id for e in entries[1:]]\n",
        "        #print(self.buffer)\n",
        "        self.arcs = [(-1, '') for _ in entries]\n",
        "        self.lm = [-1 for _ in entries]  # left-most modifier\n",
        "        self.rm = [-1 for _ in entries]  # right-most modifier\n",
        "        self.lm2 = [-1 for _ in entries]  # 2nd left-most modifier\n",
        "        self.rm2 = [-1 for _ in entries]  # 2nd right-most modifier\n",
        "\n",
        "    def next_gold_action(self):\n",
        "        if len(self.stack) < 2:\n",
        "            assert len(self.buffer)>0\n",
        "            return 'SHIFT', None\n",
        "        else:\n",
        "            s0 = self.stack[-1] if len(self.stack) > 0 else None\n",
        "            s1 = self.stack[-2] if len(self.stack) > 1 else None\n",
        "\n",
        "            if s0 == self.entries[s1].head:\n",
        "                return 'LEFT-ARC', self.entries[s1].relation\n",
        "            elif s1 == self.entries[s0].head:\n",
        "                valence_complete = True\n",
        "                for j in self.buffer:\n",
        "                    if self.entries[j].head == s0:\n",
        "                        valence_complete = False\n",
        "                        break\n",
        "                if valence_complete:\n",
        "                    return 'RIGHT-ARC', self.entries[s0].relation\n",
        "                else:\n",
        "                    assert len(self.buffer) > 0\n",
        "                    return 'SHIFT', None\n",
        "            else:\n",
        "                assert len(self.buffer) > 0\n",
        "                return 'SHIFT', None\n",
        "\n",
        "    def do(self, action, label=''):\n",
        "        if action == 'SHIFT':\n",
        "            self.stack.append(self.buffer.pop(0))\n",
        "        elif action == 'RIGHT-ARC':\n",
        "            if self.rm[self.stack[-2]] != -1:\n",
        "                self.rm2[self.stack[-2]] = self.rm[self.stack[-2]]\n",
        "            self.rm[self.stack[-2]] = self.stack[-1]\n",
        "            self.arcs[self.stack[-1]] = self.stack[-2], label\n",
        "            self.stack.pop(-1)\n",
        "        elif action == 'LEFT-ARC':\n",
        "            if self.lm[self.stack[-1]] == -1 or self.lm[self.stack[-1]] > self.stack[-2]:\n",
        "                if self.lm[self.stack[-1]] != -1:\n",
        "                    self.lm2[self.stack[-1]] = self.lm[self.stack[-1]]\n",
        "                self.lm[self.stack[-1]] = self.stack[-2]\n",
        "            self.arcs[self.stack[-2]] = self.stack[-1], label\n",
        "            self.stack.pop(-2)\n",
        "\n",
        "    def doable_actions(self):\n",
        "        actions = set()\n",
        "        if len(self.buffer) > 0:\n",
        "            actions.add('SHIFT')\n",
        "        if len(self.stack) >= 2:\n",
        "            actions.add('RIGHT-ARC')\n",
        "        if len(self.stack) >= 2 and self.stack[-2] != 0:\n",
        "            actions.add('LEFT-ARC')\n",
        "        return actions\n",
        "\n",
        "    def is_terminal_state(self):\n",
        "        return len(self.stack) == 1 and len(self.buffer) == 0\n",
        "\n",
        "    def feature_ids(self):\n",
        "        s0 = self.stack[-1] if len(self.stack) > 0 else None\n",
        "        s1 = self.stack[-2] if len(self.stack) > 1 else None\n",
        "        s2 = self.stack[-3] if len(self.stack) > 2 else None\n",
        "        s3 = self.stack[-4] if len(self.stack) > 3 else None\n",
        "        b0 = self.buffer[0] if len(self.buffer) > 0 else None\n",
        "        b1 = self.buffer[1] if len(self.buffer) > 1 else None\n",
        "        b2 = self.buffer[2] if len(self.buffer) > 2 else None\n",
        "        b3 = self.buffer[3] if len(self.buffer) > 3 else None\n",
        "        s0l = self.lm[s0] if s0 and self.lm[s0] > -1 else None\n",
        "        s1l = self.lm[s1] if s1 and self.lm[s1] > -1 else None\n",
        "        s0r = self.rm[s0] if s0 and self.rm[s0] > -1 else None\n",
        "        s1r = self.rm[s1] if s1 and self.rm[s1] > -1 else None\n",
        "        s0l2 = self.lm2[s0] if s0 and self.lm2[s0] > -1 else None\n",
        "        s1l2 = self.lm2[s1] if s1 and self.lm2[s1] > -1 else None\n",
        "        s0r2 = self.rm2[s0] if s0 and self.rm2[s0] > -1 else None\n",
        "        s1r2 = self.rm2[s1] if s1 and self.rm2[s1] > -1 else None\n",
        "        s0r1r1 = self.rm[s0r] if s0r and self.rm[s0r]>-1 else None\n",
        "        s1r1r1 = self.rm[s1r] if s1r and self.rm[s1r]>-1 else None\n",
        "        s0l1l1 = self.lm[s0l] if s0l and self.lm[s0l] > -1 else None\n",
        "        s1l1l1 = self.lm[s1l] if s1l and self.lm[s1l] > -1 else None\n",
        "        return [s0,s1,s2,s3,b0,b1,b2,b3,s0l,s1l,s0r,s1r,s0l2,s1l2,s0r2,s1r2,s0r1r1,s1r1r1,s0l1l1,s1l1l1]\n",
        "\n",
        "    def features(self):\n",
        "        feats = self.feature_ids()\n",
        "        word_feats, pos_feats, label_feats = [], [], []\n",
        "        for i,f in enumerate(feats):\n",
        "            word_feats.append(self.entries[f].form) if f is not None else word_feats.append('<null>')\n",
        "            pos_feats.append(self.entries[f].pos) if f is not None else pos_feats.append('<null>')\n",
        "            if i>=8:\n",
        "                label_feats.append(self.arcs[f][1]) if f and self.arcs[f][0]!=-1 is not None else label_feats.append('<null>')\n",
        "        return word_feats, pos_feats, label_feats\n",
        "\n",
        "    def preprocess_score(self, scores, rlabel):\n",
        "        '''\n",
        "        With respect to possible actions\n",
        "        :param scores:\n",
        "        :return:\n",
        "        '''\n",
        "        da = self.doable_actions()\n",
        "        can_shift = True if 'SHIFT' in da else False\n",
        "        can_left_arc = True if 'LEFT-ARC' in da else False\n",
        "        can_right_arc = True if 'RIGHT-ARC' in da else False\n",
        "        for i in range(len(scores)):\n",
        "            if not can_shift and rlabel[i] == 'SHIFT':\n",
        "                scores[i] = -float('inf')\n",
        "            elif not can_left_arc and rlabel[i].startswith('LEFT-ARC'):\n",
        "                scores[i] = -float('inf')\n",
        "            elif not can_right_arc and rlabel[i].startswith('RIGHT-ARC'):\n",
        "                scores[i] = -float('inf')\n",
        "\n",
        "    @staticmethod\n",
        "    def parse(sen, rlabel, score_fn):\n",
        "        conf = Configuration(sen)\n",
        "        while not conf.is_terminal_state():\n",
        "            wf, pf, lf = conf.features()\n",
        "            scores = score_fn(wf + pf + lf)\n",
        "            conf.preprocess_score(scores, rlabel)\n",
        "            best_act = np.argmax(scores)\n",
        "            act, label = 'SHIFT', ''\n",
        "            if rlabel[best_act] != 'SHIFT':\n",
        "                act, label = rlabel[best_act].split(':')\n",
        "            conf.do(act, label)\n",
        "        return conf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZTjkcyowcO5Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re, codecs\n",
        "class DependencyToken:\n",
        "    def __init__(self, id, form, lemma, pos, cpos, feats=None, parent_id=None, relation=None, deps=None, misc=None):\n",
        "        self.id = id\n",
        "        self.form = form\n",
        "        self.norm = normalize(form)\n",
        "        self.cpos = cpos\n",
        "        self.pos = pos\n",
        "        self.head = parent_id\n",
        "        self.relation = relation\n",
        "\n",
        "        self.lemma = lemma\n",
        "        self.feats = feats\n",
        "        self.deps = deps\n",
        "        self.misc = misc\n",
        "\n",
        "    def __str__(self):\n",
        "        values = [str(self.id), self.form, self.lemma, self.cpos, self.pos, self.feats,\n",
        "                  str(self.head), self.relation, self.deps, self.misc]\n",
        "        return u'\\t'.join([u'_' if v is None else v for v in values])\n",
        "\n",
        "\n",
        "def traverse(rev_head, h, visited):\n",
        "    if rev_head.has_key(h):\n",
        "        for d in rev_head[h]:\n",
        "            if d in visited:\n",
        "                return True\n",
        "            visited.append(d)\n",
        "            traverse(rev_head, d, visited)\n",
        "    return False\n",
        "\n",
        "\n",
        "def is_projective(heads):\n",
        "    '''\n",
        "    Decides if the set of heads for tree is projective.\n",
        "    :param heads:\n",
        "    :return: True if projective, else False.\n",
        "    '''\n",
        "    rev_head = defaultdict(list)\n",
        "    for dep1 in range(1, len(heads) + 1):\n",
        "        head1 = heads[dep1 - 1]\n",
        "        if head1 >= 0:\n",
        "            rev_head[head1].append(dep1)\n",
        "\n",
        "    visited = list()\n",
        "    if traverse(rev_head, 0, visited):\n",
        "        return False\n",
        "    if len(visited) < len(heads):\n",
        "        return False\n",
        "\n",
        "    root_n = 0\n",
        "    for dep1 in range(1, len(heads) + 1):\n",
        "        head1 = heads[dep1 - 1]\n",
        "\n",
        "        if rev_head.has_key(dep1):\n",
        "            for d2 in rev_head[dep1]:\n",
        "                if (d2 < head1 < dep1) or (d2 > head1 > dep1) and head1 > 0:\n",
        "                    return False\n",
        "\n",
        "        if head1 == 0:\n",
        "            root_n += 1\n",
        "        for dep2 in range(1, len(heads) + 1):\n",
        "            head2 = heads[dep2 - 1]\n",
        "            if head1 == -1 or head2 == -1:\n",
        "                continue\n",
        "            if dep1 > head1 != head2:\n",
        "                if dep2 > dep1 > head2 > head1:\n",
        "                    return False\n",
        "                if head2 > dep1 > dep2 > head1:\n",
        "                    return False\n",
        "            if dep1 < head1 != head2:\n",
        "                if dep2 > head1 > head2 > dep1:\n",
        "                    return False\n",
        "                if head2 > head1 > dep2 > dep1:\n",
        "                    return False\n",
        "    if root_n != 1:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def read_conll(fh, test=False):\n",
        "    '''\n",
        "    This function reads a CoNLL file and returns a list of @ConllEntry objects.\n",
        "    :param fh: file\n",
        "    :return: a list of @ConllEntry objects\n",
        "    '''\n",
        "    root = DependencyToken(0, '<root>', '<root>', '<root>', '<root>', '_', -1, 'rroot', '_', '_')\n",
        "    tokens = [root]\n",
        "    for line in codecs.open(fh, 'r', encoding='UTF-8'):\n",
        "        tok = line.strip().split('\\t')\n",
        "        if not tok or line.strip() == '':\n",
        "            if len(tokens) > 1: yield tokens\n",
        "            tokens = [root]\n",
        "        else:\n",
        "            if line[0] == '#' or '-' in tok[0] or '.' in tok[0]:\n",
        "                tokens.append(line.strip())\n",
        "            else:\n",
        "                tokens.append(DependencyToken(int(tok[0]), tok[1], tok[2], tok[3], tok[4], tok[5],\n",
        "                                             -1 if test else int(tok[6]) if tok[6] != '_' else -1,'_'  if test else tok[7], tok[8], tok[9]))\n",
        "    if len(tokens) > 1:\n",
        "        yield tokens\n",
        "\n",
        "\n",
        "def write_conll(fn, conll_gen):\n",
        "    '''\n",
        "    Writes a conll file\n",
        "    :param fn: output path.\n",
        "    :param conll_gen: Generator for conll file (a list of @ConllEntry objects).\n",
        "    :return:\n",
        "    '''\n",
        "    with codecs.open(fn, 'w', encoding='utf-8') as fh:\n",
        "        for sentence in conll_gen:\n",
        "            for entry in sentence[1:]:\n",
        "                fh.write(str(entry) + u'\\n')\n",
        "            fh.write('\\n')\n",
        "\n",
        "\n",
        "def eval(gold, predicted):\n",
        "    '''\n",
        "    Evaluates the output vs. gold.\n",
        "    :param gold: Gold Conll file.\n",
        "    :param predicted: Predicted Conll file.\n",
        "    :return: Unlabeled attachment accuracy (UAS), labeled attachment accuracy (LAS).\n",
        "    '''\n",
        "    correct_deps, correct_l, all_deps = 0, 0, 0\n",
        "    r2 = open(predicted, 'r')\n",
        "    for l1 in open(gold, 'r'):\n",
        "        s1 = l1.strip().split('\\t')\n",
        "        s2 = r2.readline().strip().split('\\t')\n",
        "        if len(s1) > 6:\n",
        "            if not is_punc(s2[3]):\n",
        "                all_deps += 1\n",
        "                if s1[6] == s2[6]:\n",
        "                    correct_deps += 1\n",
        "                    if s1[7] == s2[7]:\n",
        "                        correct_l += 1\n",
        "    return 100 * float(correct_deps) / all_deps, 100 * float(correct_l) / all_deps\n",
        "\n",
        "\n",
        "numberRegex = re.compile(\"[0-9]+|[0-9]+\\\\.[0-9]+|[0-9]+[0-9,]+\");\n",
        "\n",
        "\n",
        "def normalize(word):\n",
        "    return 'NUM' if numberRegex.match(word) else word.lower()\n",
        "\n",
        "\n",
        "def is_punc(pos):\n",
        "    return pos == '.' or pos == 'PUNC' or pos == 'PUNCT' or \\\n",
        "           pos == \"#\" or pos == \"''\" or pos == \"(\" or \\\n",
        "           pos == \"[\" or pos == \"]\" or pos == \"{\" or pos == \"}\" or \\\n",
        "           pos == \"\\\"\" or pos == \",\" or pos == \".\" or pos == \":\" or \\\n",
        "           pos == \"``\" or pos == \"-LRB-\" or pos == \"-RRB-\" or pos == \"-LSB-\" or \\\n",
        "           pos == \"-RSB-\" or pos == \"-LCB-\" or pos == \"-RCB-\" or pos == '\"' or pos == ')'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d1OZbKN-cY8H",
        "colab_type": "code",
        "outputId": "9ae0f2bc-bfbb-4d98-e67c-238af746df49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "input_p = \"/content/drive/My Drive/NLP/trees/dev.conll\"\n",
        "output_p = \"/content/drive/My Drive/NLP/output_dev\"\n",
        "dataset = DataSet()\n",
        "tag2action = dict(zip(dataset.vocabs_action.iloc[:,1], dataset.vocabs_action.iloc[:,0]))\n",
        "\n",
        "m = DepModel()\n",
        "Decoder(m.score, m.actions).parse(input_p, output_p)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100...200...300...400...500...600...700...800...900...1000...1100...1200...1300...1400...1500...1600...1700...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}