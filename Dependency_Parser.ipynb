{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dependency_Parser.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MangoHaha/NLP-dependency-parsing/blob/master/Dependency_Parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTNI4SD8tmmk",
        "colab_type": "code",
        "outputId": "daa31a50-4d65-49d9-a32a-5370cd7623cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYuAgrsNT4XW",
        "colab_type": "code",
        "outputId": "98c82b18-84e8-41f1-b8fa-79bbca6381ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "!pip install dynet\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dynet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/2c/6b773466b4cca5092b3fac49969011a720e6ca7b01bcfd286ac412a62971/dyNET-2.1-cp27-cp27mu-manylinux1_x86_64.whl (27.9MB)\n",
            "\u001b[K     |████████████████████████████████| 27.9MB 55.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from dynet) (1.16.3)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python2.7/dist-packages (from dynet) (0.29.7)\n",
            "Installing collected packages: dynet\n",
            "Successfully installed dynet-2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB8cUnbUW0Mq",
        "colab_type": "text"
      },
      "source": [
        "## DataSet Prepare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXoklQCeyWUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVoUMjpYyAS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataSet:\n",
        "  \n",
        "  \n",
        "  def __init__(self): \n",
        "    self.dev_data = pd.read_csv('/content/drive/My Drive/NLP/data/dev.data', sep=\" \", header=None)\n",
        "    self.train_data = pd.read_csv('/content/drive/My Drive/NLP/data/train.data', sep=\" \", header=None)\n",
        "    self.vocabs_action = pd.read_csv('/content/drive/My Drive/NLP/data/vocabs.actions', sep=\" \", header=None)\n",
        "    self.vocabs_pos = pd.read_csv('/content/drive/My Drive/NLP/data/vocabs.pos', sep=\" \", header=None)\n",
        "    self.vocabs_label = pd.read_csv('/content/drive/My Drive/NLP/data/vocabs.labels', sep=\" \", header=None)\n",
        "    self.vocabs_word = pd.read_csv('/content/drive/My Drive/NLP/data/vocabs.word', sep=\" \", header=None)\n",
        "    self.word_train = self.prepare_data(self.train_data, self.vocabs_word, 0, 20)\n",
        "    self.pos_train = self.prepare_data(self.train_data, self.vocabs_pos, 20, 40)\n",
        "    self.label_train = self.prepare_data(self.train_data, self.vocabs_label, 40, 52)\n",
        "    self.action_train = self.prepare_data(self.train_data, self.vocabs_action, 52, 53)\n",
        "    self.word_dev = self.prepare_data(self.dev_data, self.vocabs_word, 0, 20)\n",
        "    self.pos_dev = self.prepare_data(self.dev_data, self.vocabs_pos, 20, 40)\n",
        "    self.label_dev = self.prepare_data(self.dev_data, self.vocabs_label, 40, 52)\n",
        "    self.action_dev = self.prepare_data(self.dev_data, self.vocabs_action, 52, 53)\n",
        "\n",
        "  def prepare_data(self, data, vocabs, start, end):\n",
        "    sub_data = data.iloc[:,start:end]\n",
        "    voc = dict(zip(vocabs.iloc[:,0], vocabs.iloc[:,1]))\n",
        "    new_array = []\n",
        "    for line in sub_data.itertuples():\n",
        "    #for line in sub_data.itertuples():\n",
        "      cur_array = []\n",
        "      for word in line[1:]:\n",
        "        if word in voc:\n",
        "          cur_array.append(voc.get(word))\n",
        "        else:\n",
        "          cur_array.append(0)\n",
        "      new_array.append(cur_array)\n",
        "    return pd.DataFrame(new_array)\n",
        "  \n",
        "  def prepare_data_predict(self, data, vocabs, start, end):\n",
        "    sub_data = data[start:end]\n",
        "    voc = dict(zip(vocabs.iloc[:,0], vocabs.iloc[:,1]))\n",
        "    new_array = []\n",
        "    #for line in sub_data.head(20).itertuples():\n",
        "    for word in sub_data:\n",
        "      if word in voc:\n",
        "        new_array.append(voc.get(word))\n",
        "      else:\n",
        "        new_array.append(1)\n",
        "    return pd.DataFrame(new_array)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flLxgbGJW9HR",
        "colab_type": "text"
      },
      "source": [
        "## Properties"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWmAk093IrN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NetProperties:\n",
        "    def __init__(self, word_embed_dim, pos_embed_dim, label_embed_dim, hidden_dim, minibatch_size, epoch, layers):\n",
        "        self.word_embed_dim = word_embed_dim\n",
        "        self.pos_embed_dim = pos_embed_dim\n",
        "        self.label_embed_dim = label_embed_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.minibatch_size = minibatch_size\n",
        "        self.epoch = epoch\n",
        "        self.layers = layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-e2F8WIXBwN",
        "colab_type": "text"
      },
      "source": [
        "## Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2q8gqLwIsle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dynet as dynet\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "class Network:\n",
        "    def __init__(self, properties, dataset):\n",
        "        self.properties = properties\n",
        "        self.dataset = dataset\n",
        "\n",
        "        # first initialize a computation graph container (or model).\n",
        "        self.model = dynet.Model()\n",
        "\n",
        "        # assign the algorithm for backpropagation updates.\n",
        "        self.updater = dynet.AdamTrainer(self.model)\n",
        "\n",
        "        # create embeddings for words and tag features.\n",
        "        self.word_embedding = self.model.add_lookup_parameters((dataset.vocabs_word.shape[0], properties.word_embed_dim))\n",
        "        self.pos_embedding = self.model.add_lookup_parameters((dataset.vocabs_pos.shape[0], properties.pos_embed_dim))\n",
        "        self.label_embedding = self.model.add_lookup_parameters((dataset.vocabs_label.shape[0], properties.label_embed_dim))\n",
        "\n",
        "\n",
        "        # assign transfer function \n",
        "        self.transfer = dynet.rectify  # can be dynet.logistic or dynet.tanh as well.\n",
        "\n",
        "        # define the input dimension for the embedding layer.\n",
        "        # here we assume to see two words after and before and current word (meaning 5 word embeddings)\n",
        "        # and to see the last two predicted tags (meaning two tag embeddings)\n",
        "        self.input_dim = 20 * (properties.word_embed_dim + properties.pos_embed_dim) + 12*properties.label_embed_dim\n",
        "\n",
        "\n",
        "        # define the hidden layer.\n",
        "        self.hidden_layer1 = self.model.add_parameters((properties.hidden_dim, self.input_dim))\n",
        "\n",
        "        # define the hidden layer bias term and initialize it as constant 0.2.\n",
        "        self.hidden_layer_bias1 = self.model.add_parameters(properties.hidden_dim, init=dynet.ConstInitializer(0.2))\n",
        "        \n",
        "        # define the hidden layer.\n",
        "        self.hidden_layer2 = self.model.add_parameters((properties.hidden_dim, properties.hidden_dim))\n",
        "\n",
        "        # define the hidden layer bias term and initialize it as constant 0.2.\n",
        "        self.hidden_layer_bias2 = self.model.add_parameters(properties.hidden_dim, init=dynet.ConstInitializer(0.2))\n",
        "\n",
        "        if self.properties.layers == 3:\n",
        "          # define the hidden layer.\n",
        "          self.hidden_layer3 = self.model.add_parameters((properties.hidden_dim, properties.hidden_dim))\n",
        "\n",
        "          # define the hidden layer bias term and initialize it as constant 0.2.\n",
        "          self.hidden_layer_bias3 = self.model.add_parameters(properties.hidden_dim, init=dynet.ConstInitializer(0.2))\n",
        "\n",
        "        # define the output weight.\n",
        "        self.output_layer = self.model.add_parameters((dataset.vocabs_action.shape[0], properties.hidden_dim))\n",
        "\n",
        "        # define the bias vector and initialize it as zero.\n",
        "        self.output_bias = self.model.add_parameters(dataset.vocabs_action.shape[0], init=dynet.ConstInitializer(0))\n",
        "\n",
        "    def build_graph_part12(self,index, word, pos, label):\n",
        "\n",
        "        # extract word embeddings and tag embeddings from features\n",
        "        word_embeds = [self.word_embedding[wid] for wid in word.iloc[index]]\n",
        "        pos_embeds = [self.pos_embedding[wid] for wid in pos.iloc[index]]\n",
        "        label_embeds = [self.label_embedding[wid] for wid in label.iloc[index]]\n",
        "\n",
        "        # concatenating all features (recall that '+' for lists is equivalent to appending two lists)\n",
        "        embedding_layer = dynet.concatenate(word_embeds + pos_embeds + label_embeds)\n",
        "        # calculating the hidden layer\n",
        "        # .expr() converts a parameter to a matrix expression in dynet (its a dynet-specific syntax).\n",
        "        embedding_layer = dynet.dropout(embedding_layer, 0.2)\n",
        "        hidden1 = self.transfer(self.hidden_layer1 * embedding_layer + self.hidden_layer_bias1)\n",
        "        hidden1 = dynet.dropout(hidden1, 0.2)\n",
        "        hidden2 = self.transfer(self.hidden_layer2 * hidden1 + self.hidden_layer_bias2)\n",
        "        hidden2 = dynet.dropout(hidden2, 0.2)\n",
        "\n",
        "        # calculating the output layer\n",
        "        output = self.output_layer * hidden2 + self.output_bias.expr()\n",
        "\n",
        "        # return the output as a dynet vector (expression)\n",
        "        return output\n",
        "      \n",
        "    def build_graph_part3(self,index, word, pos, label):\n",
        "\n",
        "        # extract word embeddings and tag embeddings from features\n",
        "        word_embeds = [self.word_embedding[wid] for wid in word.iloc[index]]\n",
        "        pos_embeds = [self.pos_embedding[wid] for wid in pos.iloc[index]]\n",
        "        label_embeds = [self.label_embedding[wid] for wid in label.iloc[index]]\n",
        "\n",
        "        # concatenating all features (recall that '+' for lists is equivalent to appending two lists)\n",
        "        embedding_layer = dynet.concatenate(word_embeds + pos_embeds + label_embeds)\n",
        "        # calculating the hidden layer\n",
        "        # .expr() converts a parameter to a matrix expression in dynet (its a dynet-specific syntax).\n",
        "        embedding_layer = dynet.dropout(embedding_layer, 0.2)\n",
        "        hidden1 = self.transfer(self.hidden_layer1 * embedding_layer + self.hidden_layer_bias1)\n",
        "        hidden1 = dynet.dropout(hidden1, 0.2)\n",
        "        hidden2 = self.transfer(self.hidden_layer2 * hidden1 + self.hidden_layer_bias2)\n",
        "        hidden2 = dynet.dropout(hidden2, 0.2)\n",
        "        hidden3 = self.transfer(self.hidden_layer3 * hidden2 + self.hidden_layer_bias3)\n",
        "        hidden3 = dynet.dropout(hidden3, 0.2)\n",
        "        # calculating the output layer\n",
        "        output = self.output_layer * hidden3 + self.output_bias.expr()\n",
        "\n",
        "        # return the output as a dynet vector (expression)\n",
        "        return output\n",
        "  \n",
        "    def predict_part12(self, word, pos, label):\n",
        "     \n",
        "        word_embeds = [self.word_embedding[wid] for wid in word]\n",
        "        pos_embeds = [self.pos_embedding[wid] for wid in pos]\n",
        "        label_embeds = [self.label_embedding[wid] for wid in label]\n",
        "        # concatenating all features (recall that '+' for lists is equivalent to appending two lists)\n",
        "        embedding_layer = dynet.concatenate(word_embeds + pos_embeds + label_embeds)\n",
        "        # calculating the hidden layer\n",
        "        # .expr() converts a parameter to a matrix expression in dynet (its a dynet-specific syntax).\n",
        "        hidden1 = self.transfer(self.hidden_layer1 * embedding_layer + self.hidden_layer_bias1)\n",
        "        hidden2 = self.transfer(self.hidden_layer2 * hidden1 + self.hidden_layer_bias2)\n",
        "        \n",
        "\n",
        "        # calculating the output layer\n",
        "        output = self.output_layer.expr() * hidden2 + self.output_bias.expr()\n",
        "\n",
        "        # return the output as a dynet vector (expression)\n",
        "        return output\n",
        "      \n",
        "    def predict_part3(self, word, pos, label):\n",
        "        \n",
        "        word_embeds = [self.word_embedding[wid] for wid in word]\n",
        "        pos_embeds = [self.pos_embedding[wid] for wid in pos]\n",
        "        label_embeds = [self.label_embedding[wid] for wid in label]\n",
        "        # concatenating all features (recall that '+' for lists is equivalent to appending two lists)\n",
        "        embedding_layer = dynet.concatenate(word_embeds + pos_embeds + label_embeds)\n",
        "        # calculating the hidden layer\n",
        "        # .expr() converts a parameter to a matrix expression in dynet (its a dynet-specific syntax).\n",
        "        hidden1 = self.transfer(self.hidden_layer1 * embedding_layer + self.hidden_layer_bias1)\n",
        "        hidden1 = dynet.dropout(hidden1, 0.2)\n",
        "        hidden2 = self.transfer(self.hidden_layer2 * hidden1 + self.hidden_layer_bias2)\n",
        "        hidden2 = dynet.dropout(hidden2, 0.2)\n",
        "        hidden3 = self.transfer(self.hidden_layer3 * hidden2 + self.hidden_layer_bias3)\n",
        "        hidden3 = dynet.dropout(hidden3, 0.2)\n",
        "        \n",
        "\n",
        "        # calculating the output layer\n",
        "        output = self.output_layer.expr() * hidden3 + self.output_bias.expr()\n",
        "\n",
        "        # return the output as a dynet vector (expression)\n",
        "        return output\n",
        "    def train(self):\n",
        "        # matplotlib config\n",
        "        loss_values = []\n",
        "        plt.ion()\n",
        "        ax = plt.gca()\n",
        "        ax.set_xlim([0, 10])\n",
        "        ax.set_ylim([0, 3])\n",
        "        plt.title(\"Loss over time\")\n",
        "        plt.xlabel(\"Minibatch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "\n",
        "        for i in range(self.properties.epoch):\n",
        "            print 'started epoch', (i+1)\n",
        "            losses = []\n",
        "\n",
        "            step = 0\n",
        "            for index in range(dataset.word_train.shape[0]):\n",
        "                gold_label = dataset.action_train.iloc[index]\n",
        "                if self.properties.layers == 3:\n",
        "                  result = self.build_graph_part3(index, dataset.word_train, dataset.pos_train, dataset.label_train)\n",
        "                else:\n",
        "                  result = self.build_graph_part12(index, dataset.word_train, dataset.pos_train, dataset.label_train)\n",
        "             \n",
        "                # getting loss with respect to negative log softmax function and the gold label.\n",
        "                loss = dynet.pickneglogsoftmax(result, gold_label)\n",
        "\n",
        "                # appending to the minibatch losses\n",
        "                losses.append(loss)\n",
        "                step += 1\n",
        "                if len(losses) >= self.properties.minibatch_size:\n",
        "                    # now we have enough loss values to get loss for minibatch\n",
        "                    minibatch_loss = dynet.esum(losses) / len(losses)\n",
        "\n",
        "                    # calling dynet to run forward computation for all minibatch items\n",
        "                    minibatch_loss.forward()\n",
        "\n",
        "                    # getting float value of the loss for current minibatch\n",
        "                    minibatch_loss_value = minibatch_loss.value()\n",
        "\n",
        "                    # printing info and plotting\n",
        "                    loss_values.append(minibatch_loss_value)\n",
        "                    if len(loss_values)%10==0:\n",
        "                        ax.set_xlim([0, len(loss_values)+10])\n",
        "                        ax.plot(loss_values)\n",
        "                        plt.draw()\n",
        "                        plt.pause(0.0001)\n",
        "                        progress = round(100 * float(step) / len(dataset.train_data), 2)\n",
        "                        print 'current minibatch loss', minibatch_loss_value, 'progress:', progress, '%'\n",
        "\n",
        "                    # calling dynet to run backpropagation\n",
        "                    minibatch_loss.backward()\n",
        "\n",
        "                    # calling dynet to change parameter values with respect to current backpropagation\n",
        "                    self.updater.update()\n",
        "\n",
        "                    # empty the loss vector\n",
        "                    losses = []\n",
        "\n",
        "                    # refresh the memory of dynet\n",
        "                    dynet.renew_cg()\n",
        "\n",
        "            # there are still some minibatch items in the memory but they are smaller than the minibatch size\n",
        "            # so we ask dynet to forget them\n",
        "            dynet.renew_cg()\n",
        "\n",
        "    def decode(self, word_dev, pos_dev, label_dev):\n",
        "\n",
        "            # running forward\n",
        "        word_dev.values.reshape(-1)\n",
        "        if self.properties.layers == 3:\n",
        "          output = self.predict_part3(word_dev.values.reshape(-1).tolist(), pos_dev.values.reshape(-1).tolist(), label_dev.values.reshape(-1).tolist())\n",
        "        else:\n",
        "          output = self.predict_part12(word_dev.values.reshape(-1).tolist(), pos_dev.values.reshape(-1).tolist(), label_dev.values.reshape(-1).tolist())\n",
        "\n",
        "            # getting list value of the output\n",
        "        scores = output.npvalue()\n",
        "\n",
        "            # refresh dynet memory (computation graph)\n",
        "        dynet.renew_cg()\n",
        "\n",
        "        return scores\n",
        "    \n",
        "    def get_oh_encoder(self, input, vocabs):\n",
        "      onehot_encoded = []\n",
        "      for index in input:\n",
        "        letter = [0 for _ in range(len(vocabs))]\n",
        "        letter[index] = 1\n",
        "        onehot_encoded.append(letter)\n",
        "      return onehot_encoded;\n",
        "\n",
        "    def load(self, filename):\n",
        "        self.model.populate(filename)\n",
        "\n",
        "    def save(self, filename):\n",
        "        self.model.save(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JftMoQZ8XFXa",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1glAYi2UJnD",
        "colab_type": "code",
        "outputId": "b6335278-b563-40d5-f134-5a0f8cee7bbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3756
        }
      },
      "source": [
        "#Part1\n",
        "prop = NetProperties(64, 32, 32, 200, 1000, 7, 2)\n",
        "dataset = DataSet();\n",
        "network = Network(prop, dataset)\n",
        "network.train()\n",
        "network.save(\"/content/drive/My Drive/NLP/trained_model/model_1.md5\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "started epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 2.46837520599 progress: 6.96 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 2.20354700089 progress: 13.91 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 1.92340815067 progress: 20.87 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 1.7982468605 progress: 27.82 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 1.51144421101 progress: 34.78 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 1.31997525692 progress: 41.74 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 1.22843074799 progress: 48.69 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 1.06608474255 progress: 55.65 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 1.03597509861 progress: 62.61 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.888092875481 progress: 69.56 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.870230972767 progress: 76.52 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.748021304607 progress: 83.47 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.654833316803 progress: 90.43 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.624938309193 progress: 97.39 %\n",
            "started epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.558618843555 progress: 4.87 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.547629654408 progress: 11.83 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.572702229023 progress: 18.78 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.52539229393 progress: 25.74 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.561942815781 progress: 32.69 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.366505414248 progress: 39.65 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.455405622721 progress: 46.61 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.471388936043 progress: 53.56 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.404324442148 progress: 60.52 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.419059664011 progress: 67.47 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.376636743546 progress: 74.43 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.30805888772 progress: 81.39 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.396000415087 progress: 88.34 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.330931693316 progress: 95.3 %\n",
            "started epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.517405867577 progress: 2.78 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.390745937824 progress: 9.74 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.332180172205 progress: 16.69 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.402960628271 progress: 23.65 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.304140686989 progress: 30.61 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.360918879509 progress: 37.56 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.318455934525 progress: 44.52 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.276745349169 progress: 51.48 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.327993839979 progress: 58.43 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.348866075277 progress: 65.39 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.291654586792 progress: 72.34 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.292146593332 progress: 79.3 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.228013619781 progress: 86.26 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.24972987175 progress: 93.21 %\n",
            "started epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.306333988905 progress: 0.7 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.381002098322 progress: 7.65 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.246502310038 progress: 14.61 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.233501791954 progress: 21.56 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.259861588478 progress: 28.52 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.284261256456 progress: 35.48 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.245053708553 progress: 42.43 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.244801521301 progress: 49.39 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.244983255863 progress: 56.34 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.327111303806 progress: 63.3 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.240928694606 progress: 70.26 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.215521410108 progress: 77.21 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.299420595169 progress: 84.17 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.221047177911 progress: 91.13 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.186252042651 progress: 98.08 %\n",
            "started epoch 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.249145701528 progress: 5.56 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.248072952032 progress: 12.52 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.236224740744 progress: 19.48 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.249918878078 progress: 26.43 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.189001739025 progress: 33.39 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.216096073389 progress: 40.35 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.193897977471 progress: 47.3 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.205503985286 progress: 54.26 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.251035511494 progress: 61.21 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.224992081523 progress: 68.17 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.189267009497 progress: 75.13 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.233265399933 progress: 82.08 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.225017338991 progress: 89.04 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.162068977952 progress: 95.99 %\n",
            "started epoch 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.211412414908 progress: 3.48 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.287461400032 progress: 10.43 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.338895648718 progress: 17.39 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.212103620172 progress: 24.35 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.22628775239 progress: 31.3 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.221185609698 progress: 38.26 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.19612455368 progress: 45.21 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.215564340353 progress: 52.17 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.188296988606 progress: 59.13 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.183519527316 progress: 66.08 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.202434539795 progress: 73.04 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.14447838068 progress: 80.0 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.149424359202 progress: 86.95 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.198383837938 progress: 93.91 %\n",
            "started epoch 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.185272887349 progress: 1.39 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.188338235021 progress: 8.35 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.151974529028 progress: 15.3 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.181977957487 progress: 22.26 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.250366449356 progress: 29.22 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.153816491365 progress: 36.17 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.151592344046 progress: 43.13 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.112843737006 progress: 50.08 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.158287599683 progress: 57.04 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.226644814014 progress: 64.0 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.15330325067 progress: 70.95 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.201495438814 progress: 77.91 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.156716436148 progress: 84.86 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.143929228187 progress: 91.82 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "current minibatch loss 0.135042473674 progress: 98.78 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZtV0nq1V7b3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Part 2\n",
        "prop = NetProperties(64, 32, 32, 400, 1000, 7, 2)\n",
        "dataset = DataSet();\n",
        "network = Network(prop, dataset)\n",
        "network.train()\n",
        "network.save(\"/content/drive/My Drive/NLP/model_2.md5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xhMtcd8ePmy",
        "colab_type": "code",
        "outputId": "3067a66f-e677-450d-fc2f-1bc51eed84ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        }
      },
      "source": [
        "#Part3\n",
        "## tune the more complex model with 3 layers, larger word embedding, \n",
        "## hidden layer dimensions\n",
        "## using dropout layers to reduce overfitting\n",
        "\n",
        "prop = NetProperties(96, 32, 32, 800, 2000, 12, 3)\n",
        "dataset = DataSet();\n",
        "network = Network(prop, dataset)\n",
        "network.train()\n",
        "network.save(\"/content/drive/My Drive/NLP/model_3.md5\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 376, in _fixed_getinnerframes\n",
            "    lines = ulinecache.getlines(file)[start:end]\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/IPython/utils/ulinecache.py\", line 37, in getlines\n",
            "    return [l.decode(encoding, 'replace') for l in lines]\n",
            "  File \"/usr/lib/python2.7/encodings/utf_8.py\", line 15, in decode\n",
            "    def decode(input, errors='strict'):\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1824\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1826\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1411\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1319\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m             )\n\u001b[1;32m   1321\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m             \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructured_traceback_parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: string index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR2wW_AgXMJa",
        "colab_type": "text"
      },
      "source": [
        "## Scoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvscNhwzb5dz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DepModel:\n",
        "    def __init__(self, layers, trained_model):\n",
        "        '''\n",
        "            You can add more arguments for examples actions and model paths.\n",
        "            You need to load your model here.\n",
        "            actions: provides indices for actions.\n",
        "            it has the same order as the data/vocabs.actions file.\n",
        "        '''\n",
        "        # if you prefer to have your own index for actions, change this.\n",
        "        self.actions = ['SHIFT', 'LEFT-ARC:rroot', 'LEFT-ARC:cc', 'LEFT-ARC:number', 'LEFT-ARC:ccomp', 'LEFT-ARC:possessive', 'LEFT-ARC:prt', 'LEFT-ARC:num', 'LEFT-ARC:nsubjpass', 'LEFT-ARC:csubj', 'LEFT-ARC:conj', 'LEFT-ARC:dobj', 'LEFT-ARC:nn', 'LEFT-ARC:neg', 'LEFT-ARC:discourse', 'LEFT-ARC:mark', 'LEFT-ARC:auxpass', 'LEFT-ARC:infmod', 'LEFT-ARC:mwe', 'LEFT-ARC:advcl', 'LEFT-ARC:aux', 'LEFT-ARC:prep', 'LEFT-ARC:parataxis', 'LEFT-ARC:nsubj', 'LEFT-ARC:<null>', 'LEFT-ARC:rcmod', 'LEFT-ARC:advmod', 'LEFT-ARC:punct', 'LEFT-ARC:quantmod', 'LEFT-ARC:tmod', 'LEFT-ARC:acomp', 'LEFT-ARC:pcomp', 'LEFT-ARC:poss', 'LEFT-ARC:npadvmod', 'LEFT-ARC:xcomp', 'LEFT-ARC:cop', 'LEFT-ARC:partmod', 'LEFT-ARC:dep', 'LEFT-ARC:appos', 'LEFT-ARC:det', 'LEFT-ARC:amod', 'LEFT-ARC:pobj', 'LEFT-ARC:iobj', 'LEFT-ARC:expl', 'LEFT-ARC:predet', 'LEFT-ARC:preconj', 'LEFT-ARC:root', 'RIGHT-ARC:rroot', 'RIGHT-ARC:cc', 'RIGHT-ARC:number', 'RIGHT-ARC:ccomp', 'RIGHT-ARC:possessive', 'RIGHT-ARC:prt', 'RIGHT-ARC:num', 'RIGHT-ARC:nsubjpass', 'RIGHT-ARC:csubj', 'RIGHT-ARC:conj', 'RIGHT-ARC:dobj', 'RIGHT-ARC:nn', 'RIGHT-ARC:neg', 'RIGHT-ARC:discourse', 'RIGHT-ARC:mark', 'RIGHT-ARC:auxpass', 'RIGHT-ARC:infmod', 'RIGHT-ARC:mwe', 'RIGHT-ARC:advcl', 'RIGHT-ARC:aux', 'RIGHT-ARC:prep', 'RIGHT-ARC:parataxis', 'RIGHT-ARC:nsubj', 'RIGHT-ARC:<null>', 'RIGHT-ARC:rcmod', 'RIGHT-ARC:advmod', 'RIGHT-ARC:punct', 'RIGHT-ARC:quantmod', 'RIGHT-ARC:tmod', 'RIGHT-ARC:acomp', 'RIGHT-ARC:pcomp', 'RIGHT-ARC:poss', 'RIGHT-ARC:npadvmod', 'RIGHT-ARC:xcomp', 'RIGHT-ARC:cop', 'RIGHT-ARC:partmod', 'RIGHT-ARC:dep', 'RIGHT-ARC:appos', 'RIGHT-ARC:det', 'RIGHT-ARC:amod', 'RIGHT-ARC:pobj', 'RIGHT-ARC:iobj', 'RIGHT-ARC:expl', 'RIGHT-ARC:predet', 'RIGHT-ARC:preconj', 'RIGHT-ARC:root']\n",
        "        # write your code here for additional parameters.\n",
        "        # feel free to add more arguments to the initializer.\n",
        "        \n",
        "        prop = NetProperties(64, 32, 32, 200, 1000, 7, 2)\n",
        "        \n",
        "        if layers == 2:\n",
        "          prop = NetProperties(64, 32, 32, 400, 1000, 7, 2)\n",
        "        elif layers == 3:\n",
        "          prop = NetProperties(96, 32, 32, 800, 2000, 12, 3)\n",
        "          \n",
        "        dataset = DataSet();\n",
        "        self.network = Network(prop, dataset)\n",
        "\n",
        "        self.network.load(trained_model)\n",
        "        self.data = DataSet()\n",
        "\n",
        "    def score(self, str_features):\n",
        "        '''\n",
        "        :param str_features: String features\n",
        "        20 first: words, next 20: pos, next 12: dependency labels.\n",
        "        DO NOT ADD ANY ARGUMENTS TO THIS FUNCTION.\n",
        "        :return: list of scores\n",
        "        '''\n",
        "        # change this part of the code.\n",
        "        word = self.data.prepare_data_predict(str_features, self.data.vocabs_word, 0, 20)\n",
        "        pos = self.data.prepare_data_predict(str_features, self.data.vocabs_pos, 20, 40)\n",
        "        label = self.data.prepare_data_predict(str_features, self.data.vocabs_label, 40, 52)\n",
        "        scores = self.network.decode(word, pos, label)\n",
        "        return scores.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkwbOnT4cD9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder:\n",
        "    def __init__(self, score_fn, rindex):\n",
        "        self.fn = score_fn\n",
        "        self.map = rindex\n",
        "\n",
        "    def parse(self, f, of):\n",
        "        outputs = []\n",
        "        for k, sen in enumerate(read_conll(f)):\n",
        "            conf = Configuration.parse(sen, self.map, self.fn)\n",
        "            for i, arc in enumerate(conf.arcs[1:]):\n",
        "               sen[i + 1].head, sen[i+1].relation = arc[0], arc[1]\n",
        "            outputs.append(sen)\n",
        "            if (k + 1) % 100 == 0:\n",
        "                sys.stdout.write(str(k + 1) + '...')\n",
        "        sys.stdout.write('\\n')\n",
        "        write_conll(of, outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWehft7_cJd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Configuration:\n",
        "    def __init__(self, entries):\n",
        "        self.stack = [0]\n",
        "        self.entries = entries\n",
        "        self.buffer = [e.id for e in entries[1:]]\n",
        "        #print(self.buffer)\n",
        "        self.arcs = [(-1, '') for _ in entries]\n",
        "        self.lm = [-1 for _ in entries]  # left-most modifier\n",
        "        self.rm = [-1 for _ in entries]  # right-most modifier\n",
        "        self.lm2 = [-1 for _ in entries]  # 2nd left-most modifier\n",
        "        self.rm2 = [-1 for _ in entries]  # 2nd right-most modifier\n",
        "\n",
        "    def next_gold_action(self):\n",
        "        if len(self.stack) < 2:\n",
        "            assert len(self.buffer)>0\n",
        "            return 'SHIFT', None\n",
        "        else:\n",
        "            s0 = self.stack[-1] if len(self.stack) > 0 else None\n",
        "            s1 = self.stack[-2] if len(self.stack) > 1 else None\n",
        "\n",
        "            if s0 == self.entries[s1].head:\n",
        "                return 'LEFT-ARC', self.entries[s1].relation\n",
        "            elif s1 == self.entries[s0].head:\n",
        "                valence_complete = True\n",
        "                for j in self.buffer:\n",
        "                    if self.entries[j].head == s0:\n",
        "                        valence_complete = False\n",
        "                        break\n",
        "                if valence_complete:\n",
        "                    return 'RIGHT-ARC', self.entries[s0].relation\n",
        "                else:\n",
        "                    assert len(self.buffer) > 0\n",
        "                    return 'SHIFT', None\n",
        "            else:\n",
        "                assert len(self.buffer) > 0\n",
        "                return 'SHIFT', None\n",
        "\n",
        "    def do(self, action, label=''):\n",
        "        if action == 'SHIFT':\n",
        "            self.stack.append(self.buffer.pop(0))\n",
        "        elif action == 'RIGHT-ARC':\n",
        "            if self.rm[self.stack[-2]] != -1:\n",
        "                self.rm2[self.stack[-2]] = self.rm[self.stack[-2]]\n",
        "            self.rm[self.stack[-2]] = self.stack[-1]\n",
        "            self.arcs[self.stack[-1]] = self.stack[-2], label\n",
        "            self.stack.pop(-1)\n",
        "        elif action == 'LEFT-ARC':\n",
        "            if self.lm[self.stack[-1]] == -1 or self.lm[self.stack[-1]] > self.stack[-2]:\n",
        "                if self.lm[self.stack[-1]] != -1:\n",
        "                    self.lm2[self.stack[-1]] = self.lm[self.stack[-1]]\n",
        "                self.lm[self.stack[-1]] = self.stack[-2]\n",
        "            self.arcs[self.stack[-2]] = self.stack[-1], label\n",
        "            self.stack.pop(-2)\n",
        "\n",
        "    def doable_actions(self):\n",
        "        actions = set()\n",
        "        if len(self.buffer) > 0:\n",
        "            actions.add('SHIFT')\n",
        "        if len(self.stack) >= 2:\n",
        "            actions.add('RIGHT-ARC')\n",
        "        if len(self.stack) >= 2 and self.stack[-2] != 0:\n",
        "            actions.add('LEFT-ARC')\n",
        "        return actions\n",
        "\n",
        "    def is_terminal_state(self):\n",
        "        return len(self.stack) == 1 and len(self.buffer) == 0\n",
        "\n",
        "    def feature_ids(self):\n",
        "        s0 = self.stack[-1] if len(self.stack) > 0 else None\n",
        "        s1 = self.stack[-2] if len(self.stack) > 1 else None\n",
        "        s2 = self.stack[-3] if len(self.stack) > 2 else None\n",
        "        s3 = self.stack[-4] if len(self.stack) > 3 else None\n",
        "        b0 = self.buffer[0] if len(self.buffer) > 0 else None\n",
        "        b1 = self.buffer[1] if len(self.buffer) > 1 else None\n",
        "        b2 = self.buffer[2] if len(self.buffer) > 2 else None\n",
        "        b3 = self.buffer[3] if len(self.buffer) > 3 else None\n",
        "        s0l = self.lm[s0] if s0 and self.lm[s0] > -1 else None\n",
        "        s1l = self.lm[s1] if s1 and self.lm[s1] > -1 else None\n",
        "        s0r = self.rm[s0] if s0 and self.rm[s0] > -1 else None\n",
        "        s1r = self.rm[s1] if s1 and self.rm[s1] > -1 else None\n",
        "        s0l2 = self.lm2[s0] if s0 and self.lm2[s0] > -1 else None\n",
        "        s1l2 = self.lm2[s1] if s1 and self.lm2[s1] > -1 else None\n",
        "        s0r2 = self.rm2[s0] if s0 and self.rm2[s0] > -1 else None\n",
        "        s1r2 = self.rm2[s1] if s1 and self.rm2[s1] > -1 else None\n",
        "        s0r1r1 = self.rm[s0r] if s0r and self.rm[s0r]>-1 else None\n",
        "        s1r1r1 = self.rm[s1r] if s1r and self.rm[s1r]>-1 else None\n",
        "        s0l1l1 = self.lm[s0l] if s0l and self.lm[s0l] > -1 else None\n",
        "        s1l1l1 = self.lm[s1l] if s1l and self.lm[s1l] > -1 else None\n",
        "        return [s0,s1,s2,s3,b0,b1,b2,b3,s0l,s1l,s0r,s1r,s0l2,s1l2,s0r2,s1r2,s0r1r1,s1r1r1,s0l1l1,s1l1l1]\n",
        "\n",
        "    def features(self):\n",
        "        feats = self.feature_ids()\n",
        "        word_feats, pos_feats, label_feats = [], [], []\n",
        "        for i,f in enumerate(feats):\n",
        "            word_feats.append(self.entries[f].form) if f is not None else word_feats.append('<null>')\n",
        "            pos_feats.append(self.entries[f].pos) if f is not None else pos_feats.append('<null>')\n",
        "            if i>=8:\n",
        "                label_feats.append(self.arcs[f][1]) if f and self.arcs[f][0]!=-1 is not None else label_feats.append('<null>')\n",
        "        return word_feats, pos_feats, label_feats\n",
        "\n",
        "    def preprocess_score(self, scores, rlabel):\n",
        "        '''\n",
        "        With respect to possible actions\n",
        "        :param scores:\n",
        "        :return:\n",
        "        '''\n",
        "        da = self.doable_actions()\n",
        "        can_shift = True if 'SHIFT' in da else False\n",
        "        can_left_arc = True if 'LEFT-ARC' in da else False\n",
        "        can_right_arc = True if 'RIGHT-ARC' in da else False\n",
        "        for i in range(len(scores)):\n",
        "            if not can_shift and rlabel[i] == 'SHIFT':\n",
        "                scores[i] = -float('inf')\n",
        "            elif not can_left_arc and rlabel[i].startswith('LEFT-ARC'):\n",
        "                scores[i] = -float('inf')\n",
        "            elif not can_right_arc and rlabel[i].startswith('RIGHT-ARC'):\n",
        "                scores[i] = -float('inf')\n",
        "\n",
        "    @staticmethod\n",
        "    def parse(sen, rlabel, score_fn):\n",
        "        conf = Configuration(sen)\n",
        "        while not conf.is_terminal_state():\n",
        "            wf, pf, lf = conf.features()\n",
        "            scores = score_fn(wf + pf + lf)\n",
        "            conf.preprocess_score(scores, rlabel)\n",
        "            best_act = np.argmax(scores)\n",
        "            act, label = 'SHIFT', ''\n",
        "            if rlabel[best_act] != 'SHIFT':\n",
        "                act, label = rlabel[best_act].split(':')\n",
        "            conf.do(act, label)\n",
        "        return conf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTjkcyowcO5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re, codecs\n",
        "class DependencyToken:\n",
        "    def __init__(self, id, form, lemma, pos, cpos, feats=None, parent_id=None, relation=None, deps=None, misc=None):\n",
        "        self.id = id\n",
        "        self.form = form\n",
        "        self.norm = normalize(form)\n",
        "        self.cpos = cpos\n",
        "        self.pos = pos\n",
        "        self.head = parent_id\n",
        "        self.relation = relation\n",
        "\n",
        "        self.lemma = lemma\n",
        "        self.feats = feats\n",
        "        self.deps = deps\n",
        "        self.misc = misc\n",
        "\n",
        "    def __str__(self):\n",
        "        values = [str(self.id), self.form, self.lemma, self.cpos, self.pos, self.feats,\n",
        "                  str(self.head), self.relation, self.deps, self.misc]\n",
        "        return u'\\t'.join([u'_' if v is None else v for v in values])\n",
        "\n",
        "\n",
        "def traverse(rev_head, h, visited):\n",
        "    if rev_head.has_key(h):\n",
        "        for d in rev_head[h]:\n",
        "            if d in visited:\n",
        "                return True\n",
        "            visited.append(d)\n",
        "            traverse(rev_head, d, visited)\n",
        "    return False\n",
        "\n",
        "\n",
        "def is_projective(heads):\n",
        "    '''\n",
        "    Decides if the set of heads for tree is projective.\n",
        "    :param heads:\n",
        "    :return: True if projective, else False.\n",
        "    '''\n",
        "    rev_head = defaultdict(list)\n",
        "    for dep1 in range(1, len(heads) + 1):\n",
        "        head1 = heads[dep1 - 1]\n",
        "        if head1 >= 0:\n",
        "            rev_head[head1].append(dep1)\n",
        "\n",
        "    visited = list()\n",
        "    if traverse(rev_head, 0, visited):\n",
        "        return False\n",
        "    if len(visited) < len(heads):\n",
        "        return False\n",
        "\n",
        "    root_n = 0\n",
        "    for dep1 in range(1, len(heads) + 1):\n",
        "        head1 = heads[dep1 - 1]\n",
        "\n",
        "        if rev_head.has_key(dep1):\n",
        "            for d2 in rev_head[dep1]:\n",
        "                if (d2 < head1 < dep1) or (d2 > head1 > dep1) and head1 > 0:\n",
        "                    return False\n",
        "\n",
        "        if head1 == 0:\n",
        "            root_n += 1\n",
        "        for dep2 in range(1, len(heads) + 1):\n",
        "            head2 = heads[dep2 - 1]\n",
        "            if head1 == -1 or head2 == -1:\n",
        "                continue\n",
        "            if dep1 > head1 != head2:\n",
        "                if dep2 > dep1 > head2 > head1:\n",
        "                    return False\n",
        "                if head2 > dep1 > dep2 > head1:\n",
        "                    return False\n",
        "            if dep1 < head1 != head2:\n",
        "                if dep2 > head1 > head2 > dep1:\n",
        "                    return False\n",
        "                if head2 > head1 > dep2 > dep1:\n",
        "                    return False\n",
        "    if root_n != 1:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def read_conll(fh, test=False):\n",
        "    '''\n",
        "    This function reads a CoNLL file and returns a list of @ConllEntry objects.\n",
        "    :param fh: file\n",
        "    :return: a list of @ConllEntry objects\n",
        "    '''\n",
        "    root = DependencyToken(0, '<root>', '<root>', '<root>', '<root>', '_', -1, 'rroot', '_', '_')\n",
        "    tokens = [root]\n",
        "    for line in codecs.open(fh, 'r', encoding='UTF-8'):\n",
        "        tok = line.strip().split('\\t')\n",
        "        if not tok or line.strip() == '':\n",
        "            if len(tokens) > 1: yield tokens\n",
        "            tokens = [root]\n",
        "        else:\n",
        "            if line[0] == '#' or '-' in tok[0] or '.' in tok[0]:\n",
        "                tokens.append(line.strip())\n",
        "            else:\n",
        "                tokens.append(DependencyToken(int(tok[0]), tok[1], tok[2], tok[3], tok[4], tok[5],\n",
        "                                             -1 if test else int(tok[6]) if tok[6] != '_' else -1,'_'  if test else tok[7], tok[8], tok[9]))\n",
        "    if len(tokens) > 1:\n",
        "        yield tokens\n",
        "\n",
        "\n",
        "def write_conll(fn, conll_gen):\n",
        "    '''\n",
        "    Writes a conll file\n",
        "    :param fn: output path.\n",
        "    :param conll_gen: Generator for conll file (a list of @ConllEntry objects).\n",
        "    :return:\n",
        "    '''\n",
        "    with codecs.open(fn, 'w', encoding='utf-8') as fh:\n",
        "        for sentence in conll_gen:\n",
        "            for entry in sentence[1:]:\n",
        "                fh.write(str(entry) + u'\\n')\n",
        "            fh.write('\\n')\n",
        "\n",
        "def eval(gold, predicted):\n",
        "    '''\n",
        "    Evaluates the output vs. gold.\n",
        "    :param gold: Gold Conll file.\n",
        "    :param predicted: Predicted Conll file.\n",
        "    :return: Unlabeled attachment accuracy (UAS), labeled attachment accuracy (LAS).\n",
        "    '''\n",
        "    correct_deps, correct_l, all_deps = 0, 0, 0\n",
        "    r2 = open(predicted, 'r')\n",
        "    for l1 in open(gold, 'r'):\n",
        "        s1 = l1.strip().split('\\t')\n",
        "        s2 = r2.readline().strip().split('\\t')\n",
        "        if len(s1) > 6:\n",
        "            if not is_punc(s2[3]):\n",
        "                all_deps += 1\n",
        "                if s1[6] == s2[6]:\n",
        "                    correct_deps += 1\n",
        "                    if s1[7] == s2[7]:\n",
        "                        correct_l += 1\n",
        "    return 100 * float(correct_deps) / all_deps, 100 * float(correct_l) / all_deps\n",
        "\n",
        "\n",
        "numberRegex = re.compile(\"[0-9]+|[0-9]+\\\\.[0-9]+|[0-9]+[0-9,]+\");\n",
        "\n",
        "\n",
        "def normalize(word):\n",
        "    return 'NUM' if numberRegex.match(word) else word.lower()\n",
        "\n",
        "\n",
        "def is_punc(pos):\n",
        "    return pos == '.' or pos == 'PUNC' or pos == 'PUNCT' or \\\n",
        "           pos == \"#\" or pos == \"''\" or pos == \"(\" or \\\n",
        "           pos == \"[\" or pos == \"]\" or pos == \"{\" or pos == \"}\" or \\\n",
        "           pos == \"\\\"\" or pos == \",\" or pos == \".\" or pos == \":\" or \\\n",
        "           pos == \"``\" or pos == \"-LRB-\" or pos == \"-RRB-\" or pos == \"-LSB-\" or \\\n",
        "           pos == \"-RSB-\" or pos == \"-LCB-\" or pos == \"-RCB-\" or pos == '\"' or pos == ')'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8nj4fs7XXRp",
        "colab_type": "text"
      },
      "source": [
        "## Executor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1OZbKN-cY8H",
        "colab_type": "code",
        "outputId": "f20fe123-b694-48fe-fd91-ea25ba7d24d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import sys\n",
        "input_p = \"/content/drive/My Drive/NLP/trees/dev.conll\"\n",
        "output_p = \"/content/drive/My Drive/NLP/dev_part1.conll\"\n",
        "trained_model = \"/content/drive/My Drive/NLP/trained_model/model_1.md5\"\n",
        "dataset = DataSet()\n",
        "tag2action = dict(zip(dataset.vocabs_action.iloc[:,1], dataset.vocabs_action.iloc[:,0]))\n",
        "\n",
        "m = DepModel(1, trained_model)\n",
        "Decoder(m.score, m.actions).parse(input_p, output_p)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100...200...300...400...500...600...700...800...900...1000...1100...1200...1300...1400...1500...1600...1700...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHqHGInveSP6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5215b480-8275-4170-ca8a-34e811451af2"
      },
      "source": [
        "uas,las = eval(\"/content/drive/My Drive/NLP/trees/dev.conll\",\"/content/drive/My Drive/NLP/output/dev_part1.conll\")\n",
        "\n",
        "print 'Unlabeled attachment score', round(uas,2)\n",
        "print 'Labeled attachment score', round(las,2)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unlabeled attachment score 85.01\n",
            "Labeled attachment score 81.92\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}